\chapter{Evaluation}

The intention behind this work has been to develop an interactive visualization that effectively portrays the MS-PROD model and its implications.  Two types of evaluations were conducted to determine which design alternatives were best for conveying this information: a formal evaluation of the arcs with novice users and an informal evaluation with expert users.  These two evaluations and the resulting findings are described in detail below. 

\section{Formal Evaluation of Dynamic Arcs}

We were interested in how different visualization alternatives enhance a user's understanding of the complex relationships between the fish species and the effects of those relationships.  In other words, is there a benefit to using dynamic, animated arcs---the most complicated representation of the relationships---over another method or even displaying no arcs at all?  To investigate this question, we designed and conducted a user study to measure the performance of different arc depiction alternatives.  The experimental conditions were as follows:
\begin{enumerate}[(A)]
\item \textbf{No arcs} - Only the time series are displayed on the screen. 
\item \textbf{Static arcs} - Arcs are drawn between the time series to show predation or competition.  The width of the arc is based on the coefficient in the input parameter file.  All arcs are drawn at all times.
\item \textbf{Dynamic arcs without animation} - The arcs change in width according to causal linkage, as described in Section~\ref{sec:arcDynamic}.
\item \textbf{Dynamic arcs with animation} - The arcs are dynamic and feature animation to help indicate the direction of the relationship.
\end{enumerate}
The ``blended'' depiction of change and absolute biomass markers were displayed in all four conditions.

Our hypothesis was that the Condition A would be the least effective, as it requires the user to guess why indirect or unexpected changes in biomass occurred since no arcs are drawn.  We also hypothesized that Conditions C and D would be more effective than Condition B, because dynamic arcs filter to show the relevant information, while static arcs show all information at once which could be overwhelming.  Finally, we hypothesized that Condition D would be at least slightly more effective than Condition C, since there are more visual cues for directionality with the animated arcs than with the non-animated arcs.

\subsection{Method}

The study was conducted at a screened-off table in a student union building at the University of New Hampshire.  A paid undergraduate research assistant conducted the study and responses from the study were graded by two paid undergraduate research assistants.

Each participant conducted the experiment task for only one of the four conditions.  The experiment began with a brief training session which was tailored according to the experimental condition---i.e., arcs were explained only for conditions B, C, and D; the meaning of dynamic arcs were explained only for conditions C and D.  Feedback about the quality of the participant's answers was given only during the training phase.  

In the remainder of the experiment, the participant followed on screen instructions to manipulate one of the sliders controlling the fish catch.  The participant then answered questions about the resulting effects and the reasons for the effects.  A single experiment lasted approximately fifteen minutes.

\subsection{Apparatus}

We conducted the experiment using a standard Dell laptop with an extra Dell monitor.  The window with the model visualization was maximized on the extra screen, while the window with the experiment questions was maximized on the laptop screen.  Participants used the mouse to interact with the model visualization and recorded their answers using the laptop keyboard and mouse.

\subsection{Participants} \label{sec:participants}

There were 80 participants who took part in the study, all of which were recruited by a poster affixed to the backside of the privacy screen.  Participants were randomly assigned to the four conditions, such that there were 20 in each condition.  They could have been undergraduate or graduate students; we only required that participants had to be at least 18 years of age.  Participants were voluntary and were compensated with a pack of pens or a notebook.  They were required to read and sign an IRB consent form before participating in the study, shown in Appendix~\ref{sec:irbConsent}.

Participants were asked to provide their gender and their college at the university.  There were 28 females and 52 males who took part in the study.  There were 31 students from College of Liberal Arts (COLA), 20 from the Peter T. Paul College of Business and Economics, 15 from the College of Life Sciences, eight from the College of Health and Human Services, five from the College of Engineering and Physical Sciences, and one from the Thompson School of Applied Sciences.  We created a pseudo-category from the reported colleges based on quantitative skills.  Students were placed in the ``low quantitative'' category if they reported being as a student of COLA and ``high quantitative'' if the were from any other school.  The reasoning was that low quantitative students were less likely to have quantitative-analytic skills.  There were 31 low quantitative students and 49 high quantitative students.

\subsection{Task}

Initially, all fishing effort sliders were set to the value of one.  Participants were instructed to increase or decrease the fishing effort of a specific functional group---e.g., \textit{``Using the sliders, double the harvest effort on elasmobranchs.''}  An example of this type of instructional window as it appeared to participants is shown in Figure~\ref{fig:eval_inst}.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{figures/png/eval_instr.png}
	\caption[An instructional window in the evaluation which guides the participant]{An instructional window in the evaluation which guides the participant.}
	\label{fig:eval_inst}
\end{figure}

Next, the participants were asked to answer one or more questions of the form, ``\textit{What was the effect on (fish species)?}''  E.g., \textit{``What was the effect on haddock?''}  All questions, as well as their answers, can be seen in Appendix~\ref{sec:questions}, grouped together by instruction.  Participants answered this ``What\ldots?''\ question with one of five options from a drop-down menu:
\begin{itemize}
\item \textit{Increased a lot}
\item \textit{Increased a little}
\item \textit{Stayed about the same}
\item \textit{Decreased a little}
\item \textit{Decreased a lot}
\end{itemize}
An example of the evaluation window with the drop-down menu as it appeared to users is shown in Figure~\ref{fig:eval_what}.

\begin{figure}
\centering

\subfigure[The drop-down for selecting ``What\ldots?''\ answers.]{\label{fig:eval_what}\includegraphics[width=0.48\textwidth]{figures/png/eval_what.png}} 
\subfigure[The text box for entering ``Why?''\ answers.]{\label{fig:eval_why}\includegraphics[width=0.48\textwidth]{figures/png/eval_why.png}}

	\caption[Examples of the windows where participants entered answers]{Examples of the windows where participants entered answers.}
	\label{fig:eval}
\end{figure}

Finally, the user was asked, ``\textit{Why? [Try to explain in no more than three sentences.]}''  A large text box was provided for the participant to type a response.  This is shown in Figure~\ref{fig:eval_why}. If this question was the last question in its set, then the sliders were all reset to one and a new instruction was given for the next set of questions until all questions were answered. 

The questions were designed to fit in one of two difficulty categories:
\begin{itemize}
\item First-order
\item Higher-order
\end{itemize}

First-order questions asked about a fish species whose biomass changed directly as a result of increased or decreased harvest effort.  In other words, the fish was a member of the functional group whose harvest effort was changed and either (a) its biomass decreased due to increased harvest effort or (b) its biomass increased due to decreased harvest effort---e.g.,  increase harvest on A $\rightarrow$ biomass of A decreases.  There were three ``Why?''\ questions of this type.

Higher-order questions concerned a fish species whose biomass changed from a second-order or third-order effect.  In this case, the fish may or may not have been a member of the functional group for which the fishing effort changed.  If the fish was a member of the functional group, then perhaps its biomass did not change as expected because of the effects of competition or predation with other members of the functional group.  If the fish was not a member of the functional group for which fishing effort changed, then its biomass may have changed because of competition or predation with a member of that functional group---e.g., increase harvest on A $\rightarrow$ biomass of A decreases $\rightarrow$ biomass of B increases because A eats B.  More complex explanations involving several inter-species relationships are also possible---e.g., increase harvest on A $\rightarrow$ biomass of A decreases $\rightarrow$ biomass of B increases because A eats B $\rightarrow$ biomass of C decreases because B eats C.  There were four higher-order ``Why?''\ questions. 

In total, there were three instructions for adjusting the harvest effort and seven pairs of ``What?''\ and ``Why?''\ questions.  All participants were given the same instructions and asked the same questions in the same order, regardless of condition.

\subsection{Results}

\begin{figure}
\centering

\subfigure[``What\ldots?''\ scores.]{\label{fig:resultsWhat}\includegraphics[width=0.32\textwidth]{figures/png/results_what.png}} 
\subfigure[First-order ``Why?''\ scores.]{\label{fig:resultsWhy1}\includegraphics[width=0.32\textwidth]{figures/png/results_why1.png}}
\subfigure[Higher-order ``Why?''\ scores.]{\label{fig:resultsWhy23}\includegraphics[width=0.32\textwidth]{figures/png/results_why23.png}}  

	\caption[Results of the formal evaluation, shown as mean scores graphed by condition]{Results of the formal evaluation, shown as mean scores graphed by condition.  Scores were assigned on a scale from 0 to 3.}
	\label{fig:results}
\end{figure}

The answers to the questions of the evaluation were graded on a scale of 0 (i.e., completely wrong) to 3 (i.e., completely correct), with partial points allowed.  ``What\ldots?''\ questions, which were answered using a drop-down, were graded automatically by a script, while ``Why?''\ questions were graded by two undergraduate graders.  The average of the two scores was taken and these averages were used in our analyses.  The correlation coefficient (Pearson's $r$) between the scores assigned by each grader was 0.744.

The summarized results of our evaluation can be found in Figure~\ref{fig:results}, where mean scores are shown by condition.  For our analyses, we divided the questions into three categories:
\begin{enumerate}
\item ``What\ldots?''\ questions (seven questions)
\item First-order ``Why?''\ questions (three questions)
\item Higher-order ``Why?''\ questions (four questions)
\end{enumerate}
Separate ANOVAs (analysis of variance) were run with Tukey HSD (Honestly Significant Differences) tests for each of these three types of questions.  There were no significant differences between the four conditions for the seven ``What\ldots?''\ questions and the three first-order ``Why?''\ questions.    However, there was a significant effect for the four conditions with the higher-order ``Why?''\ questions, shown by $(F[1, 76] = 12.6; p < 0.001)$ and the HSD test, with no other significant differences (see Figure~\ref{fig:resultsWhy23}).

\begin{figure}[h]
	\centering
	\includegraphics[width=0.85\textwidth]{figures/png/results_arts_science.png}
	\caption[Mean scores for low quantitative versus high quantitative students for the higher-order ``Why?''\ questions]{Mean scores for low quantitative versus high quantitative students for the higher-order ``Why?''\ questions.}
	\label{fig:results_arts_science}
\end{figure}

Additional ANOVAs were run to look for effects of gender and whether the student was a ``low quantitative'' or ``high quantitative'' student, as defined in Section~\ref{sec:participants}.  The gender and quantitative factors showed no significant effect for the higher-order ``Why?''\ questions according to our analyses.  Nevertheless, the quantitative effect approached significance as seen by $(F[1, 3] = 5.26; p = 0.1)$; the effects of this are illustrated in Figure~\ref{fig:results_arts_science}.

\subsection{Discussion}

Our results strongly suggest that using either static or dynamic arcs is better than using no arcs at all for asking more difficult (i.e., higher-order) questions about the complex, underlying relationships between the species.  The type of causal relationship depiction did not matter as much when it came to simpler (i.e., ``What\ldots?''\ and first-order ``Why?'') questions.  For the ``What\ldots?''\ questions, this is not surprising, as these questions were concerned with reading a change in a time series chart, for which the inter-species relationships were totally irrelevant.  Similarly, the first-order ``Why?''\ questions involved direct effects of the changes in fishing effort, so understanding of the inter-species relationships was unnecessary.  Only the higher-order questions involved the competition and/or predation relationships, leading to a significance to the presence or absence of arcs.

Though the difference in mean score between low and high quantitative students, shown in Figure~\ref{fig:results_arts_science}, was not significant, it is interesting.  In Condition A (no arcs), the mean for high quantitative students was over three times the mean for low quantitative students.  This could possibly suggest that high quantitative students were able to perform better in the absence of arcs since they have more experience with quantitative analysis and reasoning.  The gap narrowed in the other conditions; under Condition B (static arcs), high quantitative students had scores over twice as high as the low quantitative students on average, while the means were similar in Conditions C (dynamic arcs) and D (animated and dynamic arcs).  Again, this effect failed to reach significance, so no strong conclusions should be drawn, but this may imply that dynamic arcs enabled low quantitative students to produce higher quality answers.  Perhaps an evaluation with more participants would produce a significant result concerning the type of student.

Despite our efforts to provide a thorough and detailed grading key (see Appendix~\ref{sec:gradingScheme}), the correlation coefficient for the scores assigned by the two undergraduate graders was low.  Perhaps the task of assigning scores was difficult due to its subjective nature.  

\section{Informal Evaluations}

We interviewed three expert users in an informal environment in order to determine their preferences of the alternative depiction of the different features.  The informal interviews consisted of explaining and demonstrating the visualization to the participants and asking them to describe which alternative depictions they prefer, if any, and why.  Overall, the expert users who participated in the informal evaluations liked the visualization in general, particularly the dynamic, animated arcs.  More detailed findings of these informal evaluations are below; the comments were reconstructed from notes made in the meetings.

\subsection{Michael Fogerty and Robert Gamble} %Dr Fogerty

Dr.\ Michael Fogerty and Robert Gamble---members of the NOAA's National Marine Fisheries Services (NMFS) in Woods Hole, MA---are the original authors of the MS-PROD model with Jason Link.  We presented a prototype of the visualization in August 2013 and a more finalized visualization in January 2014.  The two of them have been pleased with the visualization.

Before we developed our visualization, they were using Microsoft Excel spreadsheets to graph the CSV output of the model after each run.  They reacted positively to the abilities to (a) change fishing effort parameters and see an instantaneous result and (b) easily perceive differences between forecasts that resulted from changes in fishing effort.  Dr.\ Fogerty suggested that the user should be able to set the baseline forecast at any moment, which we implemented.  Mr.\ Gamble expressed interest in keeping all alternative depictions in the final visualization, as he liked the ability to toggle between the various options.  He said he could see himself using the small multiples view to understand the relationships between the species, while he might use the four-panel view to prepare figures for future publications.

The feature that Dr.\ Fogerty and Mr.\ Gamble have been most enthusiastic about is the dynamic, animated arcs.  This feature was first demonstrated at a NMFS meeting on January 24, 2014.  Other members in attendance were also excited about the dynamic, animated arcs.  Mr.\ Gamble expressed that even sometimes he can become confused about the counter-intuitive effects of the underlying relationships and must refer to the predation and competition matrices in the original parameter file to understand them; the dynamic arcs eliminate the need for this extra work by making the relevant relationships more obvious.  Members in attendance were very interested in the potential to adapt the visualization to other models.  Furthermore, they believed the visualization would allow them to make convincing arguments to fishery managers or other important decision makers to use the MS-PROD model or similar models.

Dr.\ Michael Fogerty and Robert Gamble have been further developing the MS-PROD model to include types of fishing (e.g., bottom trawl, midwater trawl, long lines, dredges) with different catchabilities for each pair of fish species and fishing type.  They have also introduced climate factors (e.g., average sea floor temperature).  They have expressed interest in incorporating these new factors into the visualization, as well as the ability to include more species and/or functional groups.  Furthermore, Dr.\ Fogerty is interested in developing a version of the visualization that is compatible with browsers for usage by the general public.  However, Gamble expressed reluctance to use the actual names of fish species because this could result in over-interpretation of the results and suggested that generic names like ``Elasmobranch 1'' and ``Elasmobranch 2'' be used.

In general, Dr.\ Fogerty and Mr.\ Gamble were satisfied with the quality of the visualization.  Mr.\ Gamble said that he was not sure how to express what he wanted in a visualization when our collaboration began, but he saw what he had originally envisioned when he saw the finalized visualization.  

\subsection{David Goethel}

On April 1, 2014, we conducted an informal interview with David Goethel.  David Goethel is a biologist and fisherman based out of Hampton, New Hampshire, who has advised several state and federal fishery management boards and served on the New England Fishery Management Council.  As a fisherman, he catches all ten of the species used in the MS-PROD model throughout the year, as well as others.  He has been an advocate for moving toward a more sustainable approach to fishery management and is interested in models which can help illustrate that change is necessary.  

Mr.\ Goethel found both the small multiple and four panel views useful.  He did not have a preference over either view and said that he might choose which one to use depending on his intended audience or what he was investigating in the model.  Similarly, he said he liked all options for uncertainty visualization and would choose based on his audience; he might use error bands when presenting to the general public, but use box plots for fishery managers.  He had previously believed that stock assessments should be presented more like hurricane tracks, with multiple forecasts to show multiple opinions, therefore he found the range of forecasts shown in the uncertainty view to be particularly helpful.

As for the different depictions of change, Mr.\ Goethel preferred the blended, shaded area between the two forecasts over instantaneous change only or the dotted line for the previous forecast.  He said he would always use the blended option because it was more informative.  For understanding the relationships between fish, he preferred the dynamic, animated arc over all other options.  This option allows the user to ``follow the flow [of the relationships] more easily,'' while he found it ``harder to see the conclusion'' of the effects of the harvest without animation.  He was excited to see a visualization of these relationships because they can be counter-intuitive even to someone with as much experience as him.

Overall, Mr.\ Goethel was interested in the model, saying that its visualization would help to convince people that more complex models like MS-PROD are necessary.  He said fishery managers typically prefer single species models and make decisions for ten-year periods.  However, Mr.\ Goethel finds it important to consider multiple species as well as other factors and to think about management for longer time periods, like MS-PROD does.  He said that MS-PROD ``might reflect reality more,'' and our visualization might help to persuade managers of this.  He recommended restricting access to the model to the scientific community only for now and waiting before presenting it to the general public to avoid unexperienced users from drawing incorrect conclusions.
